{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "from datetime import timedelta\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorded FEMA Disasters (through 2018)\n",
    "fema_disaster = pd.read_csv('https://www.dropbox.com/s/csf8o84x2olw7n2/clean_fema_data?dl=1')\n",
    "\n",
    "# Quaterly Work Indicators (through Q1 2018)\n",
    "qwi = pd.read_csv('https://www.dropbox.com/s/fuvc3s6d40ydc45/master_qwi_2003_2018.csv?dl=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set datetime index\n",
    "qwi.index = pd.DatetimeIndex(qwi['time'].values)\n",
    "\n",
    "# Select relevant columns\n",
    "qwi = qwi[['EarnS','FrmJbLs','HirAs', 'county', 'county_codes', 'county_name', 'state', 'state_abv', 'time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 2003 - 2018 in FEMA Disasters\n",
    "\n",
    "# Select years\n",
    "disaster_time = [2003, 2004, 2005, 2006, 2007, 2008, 2009,\n",
    "                2010, 2011, 2012, 2013, 2014, 2015, 2016,\n",
    "                2017, 2018]\n",
    "\n",
    "disaster_time = '|'.join(str(q) for q in disaster_time)\n",
    "\n",
    "# Filter time between 2003 - 2018\n",
    "fema_disaster_2003_2018 = fema_disaster[fema_disaster['time'].str.contains(disaster_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine top disaster locations (states)\n",
    "disaster_count = fema_disaster_2003_2018['State '].value_counts().sort_values(ascending = False)\n",
    "\n",
    "# Select top 10 states\n",
    "disaster_top_10_states = disaster_count[0:10]\n",
    "\n",
    "# Convert to list with pipe seperator\n",
    "disaster_top_10_states = disaster_top_10_states.index.tolist()\n",
    "\n",
    "disaster_top_10_states_joined = '|'.join(s for s in disaster_top_10_states)\n",
    "\n",
    "# Isolate top 10 disaster states in QWI\n",
    "qwi_top_10 = qwi[qwi['state_abv'].str.contains(disaster_top_10_states_joined)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashleywhite/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Determine top disaster locations (counties)\n",
    "\n",
    "# Concat State & County\n",
    "fema_disaster_2003_2018['county_state'] = fema_disaster_2003_2018['State '].astype(str) + \\\n",
    "'-' + fema_disaster_2003_2018['Declared County/Area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort states / counties with largest numbers of disasters\n",
    "county_disaster_count = fema_disaster_2003_2018.groupby(['county_state', 'State ']) \\\n",
    "['Disaster Number'].count().sort_values(ascending = False)\n",
    "\n",
    "# Index top 100 counties by disaster count\n",
    "county_disaster_count_100 = county_disaster_count[:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of disaster by county type\n",
    "county_disaster_count_100_df = pd.DataFrame(county_disaster_count_100)\n",
    "\n",
    "county_disaster_count_100_df = county_disaster_count_100_df.stack().reset_index()\n",
    "\n",
    "county_disaster_count_100_df.rename({0: 'disaster_count'}, axis = 1, inplace = True)\n",
    "\n",
    "county_disaster_count_100_df.drop(columns = 'level_2', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extraneous characters\n",
    "county_disaster_count_100_df['county_state'] = [x.replace('(County)', '') for x in county_disaster_count_100_df['county_state']]\n",
    "county_disaster_count_100_df['county_state'] = [x.replace('(Parish)', '') for x in county_disaster_count_100_df['county_state']]\n",
    "county_disaster_count_100_df['county_state'] = [x.split('-')[1] for x in county_disaster_count_100_df['county_state']]\n",
    "county_disaster_count_100_df['county_state'] = [re.sub('[(]\\S*[)]', '', x) for x in county_disaster_count_100_df['county_state']]\n",
    "county_disaster_count_100_df['county_state'] = [re.sub('[(].*[)]', '', x) for x in county_disaster_count_100_df['county_state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target columns\n",
    "targets = ['EarnS', 'HirAs', 'FrmJbLsS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter QWI for top 100 counties\n",
    "top_100_counties = qwi[(qwi['county_name'].str.contains(county_disaster_count_100_df['county_state'][0])) & \\\n",
    "    (qwi['state_abv'] == county_disaster_count_100_df['State '][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_counties = pd.DataFrame(top_100_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(county_disaster_count_100_df)):\n",
    "\n",
    "    temp_df = qwi[(qwi['county_name'].str.contains(county_disaster_count_100_df['county_state'][i])) & \\\n",
    "    (qwi['state_abv'] == county_disaster_count_100_df['State '][i])]\n",
    "\n",
    "    top_100_counties = pd.concat([top_100_counties, temp_df])\n",
    "\n",
    "top_100_counties.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_counties.to_csv('../project-4/data/top_100_counties_disaster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create blank index for predictions\n",
    "end_old_index = top_100_counties.index[-1]\n",
    "\n",
    "new_index = pd.date_range(end_old_index, periods = 8, freq = 'QS')\n",
    "\n",
    "new_index  = new_index[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = pd.DataFrame(columns = top_100_counties.columns, index = new_index)\n",
    "#blank.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in top_100_counties.iterrows():\n",
    "    df = pd.DataFrame(columns = top_100_counties.columns, index = new_index)\n",
    "\n",
    "    #df.fillna(0, inplace = True)\n",
    "    \n",
    "    df.iloc[:, 5] = row['county_name']\n",
    "    df.iloc[:, 7] = row['state_abv']\n",
    "    \n",
    "    \n",
    "    blank = pd.concat([blank, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank['time'] = blank.index\n",
    "\n",
    "blank = blank[~ blank['county_name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_counties = pd.concat([top_100_counties, blank])\n",
    "\n",
    "top_100_counties.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EarnS', 'FrmJbLs', 'HirAs', 'county', 'county_codes', 'county_name',\n",
       "       'state', 'state_abv', 'time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100_counties.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_counties['county_name'] = [str(x).strip() for x in top_100_counties['county_name']]\n",
    "\n",
    "counties = top_100_counties['county_name'].value_counts().index\n",
    "\n",
    "county_df = top_100_counties[top_100_counties['county_name'] == counties[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / test split\n",
    "county_df_train = county_df.\n",
    "\n",
    "\n",
    "county_df_test = qwi_LA_county.iloc[int(qwi_LA_county.shape[0] * .90):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima = ARIMA(endog = top_100_counties[targets[0]],\n",
    "                 order = (final_p, final_d, final_q))\n",
    "\n",
    "# Fit SARIMA model.\n",
    "model = arima.fit()\n",
    "\n",
    "# Generate predictions based on test set.\n",
    "preds = model.predict(start = start, end = end - 1)\n",
    "\n",
    "# Evaluate predictions.\n",
    "print(mean_absolute_error(qwi_LA_county_test['FrmJbLsS'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data.\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(label = f'Average Job Loss w/ ARIMA ({final_p}, {final_d}, {final_q}) Predictions', fontsize=16);\n",
    "sns.lineplot(data=qwi_LA_county_train['FrmJbLsS'], color=\"coral\", label=\"Average Job Loss (Train)\")\n",
    "sns.lineplot(data=qwi_LA_county_test['FrmJbLsS'], color=\"seagreen\", label=\"Average Job Loss (Test)\")\n",
    "sns.lineplot(x = qwi_LA_county_test.index, y = preds.values, color = 'darkred')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
